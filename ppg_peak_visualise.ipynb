{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 임포트\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# 기존 Firebase 앱이 있으면 삭제하고 새로 초기화\n",
    "if firebase_admin._apps:\n",
    "    firebase_admin.delete_app(firebase_admin.get_app())\n",
    "\n",
    "# Firebase 앱 초기화 (사용자의 키와 URL로 수정 필요)\n",
    "cred = credentials.Certificate(\"hrvdataset-firebase-adminsdk-oof96-2a96d6ac7f.json\")  # Firebase Admin SDK JSON 파일\n",
    "firebase_admin.initialize_app(cred, {\"databaseURL\": \"https://hrvdataset-default-rtdb.firebaseio.com/\"})\n",
    "\n",
    "# 데이터 가져오기\n",
    "# ref = db.reference(\"HeartRateData\")\n",
    "# data = ref.get()\n",
    "\n",
    "# wakeup.json 파일에서 데이터 불러오기\n",
    "with open(\"gosleep.json\", \"r\") as f:\n",
    "    data_json = json.load(f)\n",
    "\n",
    "\n",
    "# 데이터 정리\n",
    "ppg_values = []\n",
    "timestamps = []\n",
    "\n",
    "for key, value in data_json[\"HeartRateData\"].items():\n",
    "    if not value[\"isError\"]:  # 오류 없는 데이터만 사용\n",
    "        ppg_values.append(value[\"ppgGreen\"])\n",
    "        timestamps.append(pd.to_datetime(value[\"timestamp\"]))\n",
    "\n",
    "# 데이터프레임 생성 및 정렬\n",
    "df = pd.DataFrame({\"Timestamp\": timestamps, \"PPG\": ppg_values})\n",
    "df = df.sort_values(\"Timestamp\")\n",
    "\n",
    "# 초반 2초 데이터 삭제\n",
    "start_time = df[\"Timestamp\"].iloc[0]\n",
    "df = df[df[\"Timestamp\"] > start_time + pd.Timedelta(seconds=2)]\n",
    "\n",
    "# PPG 신호 청소 (샘플링 주파수 25Hz)\n",
    "fs = 25\n",
    "ppg_cleaned = nk.ppg_clean(df[\"PPG\"], sampling_rate=fs)\n",
    "\n",
    "# 피크 검출 함수 (min_y 추가)\n",
    "def find_prominent_peaks(signal, threshold=0.1, min_y=0):\n",
    "    peaks = []\n",
    "    for i in range(1, len(signal) - 1):\n",
    "        if signal[i] > signal[i - 1] and signal[i] > signal[i + 1] and signal[i] > min_y:\n",
    "            left_min = min(signal[max(0, i - 5):i])\n",
    "            right_min = min(signal[i + 1:i + 6])\n",
    "            prominence = signal[i] - max(left_min, right_min)\n",
    "            if prominence > threshold:\n",
    "                peaks.append(i)\n",
    "    return peaks\n",
    "\n",
    "# 피크 검출\n",
    "min_y = 0\n",
    "peaks_indices = find_prominent_peaks(ppg_cleaned, threshold=0.1, min_y=min_y)\n",
    "\n",
    "\n",
    "# 피크의 타임스탬프와 값 추출\n",
    "peaks_timestamps = df[\"Timestamp\"].iloc[peaks_indices].values\n",
    "peaks_values = ppg_cleaned[peaks_indices]\n",
    "\n",
    "# RR 간격 계산 (밀리초 단위)\n",
    "rr_intervals = np.diff(peaks_timestamps).astype('timedelta64[ms]').astype(int)\n",
    "\n",
    "# RR 간격을 다시 피크 인덱스로 변환\n",
    "peaks_from_rr = nk.intervals_to_peaks(rr_intervals)\n",
    "\n",
    "# PPG 피크 검출\n",
    "peaks, info = nk.ppg_peaks(ppg_cleaned, sampling_rate=fs, show=True)\n",
    "\n",
    "# peaks 데이터프레임의 인덱스를 df와 일치시키기\n",
    "peaks[\"Timestamp\"] = df[\"Timestamp\"].reset_index(drop=True)\n",
    "\n",
    "# HRV 도메인별 분석\n",
    "hrv_time_metrics = nk.hrv_time(peaks_from_rr, sampling_rate=1000)\n",
    "hrv_frequency_metrics = nk.hrv_frequency(peaks_from_rr, sampling_rate=1000)\n",
    "hrv_nonlinear_metrics = nk.hrv_nonlinear(peaks_from_rr, sampling_rate=1000)\n",
    "\n",
    "# HRV 지표 출력\n",
    "print(\"HRV Time-Domain Metrics:\")\n",
    "print(hrv_time_metrics)\n",
    "print(\"\\nHRV Frequency-Domain Metrics:\")\n",
    "print(hrv_frequency_metrics)\n",
    "print(\"\\nHRV Non-Linear Metrics:\")\n",
    "print(hrv_nonlinear_metrics)\n",
    "\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[\"Timestamp\"], ppg_cleaned, label=\"Cleaned PPG\", color=\"blue\")\n",
    "plt.scatter(peaks_timestamps, peaks_values, color=\"red\", label=\"Peaks\", zorder=3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"PPG Signal\")\n",
    "plt.title(\"PPG Signal with Detected Peaks\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import chi2, f\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import chi2, f\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# 0. Firebase 앱 초기화 및 데이터 로드\n",
    "# ---------------------------\n",
    "\n",
    "# 기존 Firebase 앱 초기화 (필요 시)\n",
    "if firebase_admin._apps:\n",
    "    firebase_admin.delete_app(firebase_admin.get_app())\n",
    "\n",
    "# Firebase 앱 초기화 (사용자의 키와 URL로 수정 필요)\n",
    "cred = credentials.Certificate(\"hrvdataset-firebase-adminsdk-oof96-2a96d6ac7f.json\")\n",
    "firebase_admin.initialize_app(cred, {\"databaseURL\": \"https://hrvdataset-default-rtdb.firebaseio.com/\"})\n",
    "\n",
    "# 데이터 가져오기\n",
    "# ref = db.reference(\"HeartRateData\")\n",
    "# data = ref.get()\n",
    "\n",
    "# gosleep.json 파일에서 데이터 불러오기 (firebase와 동일한 형식)\n",
    "with open(\"test.json\", \"r\") as file_in:\n",
    "    data_json = json.load(file_in)\n",
    "\n",
    "# ---------------------------\n",
    "# 1. PPG 데이터 처리 및 HRV 분석 (기존 방식)\n",
    "# ---------------------------\n",
    "\n",
    "# 데이터 정리 (오류 없는 데이터만 사용)\n",
    "ppg_values = []\n",
    "ppg_timestamps = []\n",
    "for key, value in data_json[\"HeartRateData\"].items():\n",
    "    if not value[\"isError\"]:\n",
    "        ppg_values.append(value[\"ppgGreen\"])\n",
    "        ppg_timestamps.append(pd.to_datetime(value[\"timestamp\"]))\n",
    "\n",
    "# 데이터프레임 생성 및 타임스탬프 기준 정렬\n",
    "df_ppg = pd.DataFrame({\"Timestamp\": ppg_timestamps, \"PPG\": ppg_values})\n",
    "df_ppg = df_ppg.sort_values(\"Timestamp\")\n",
    "\n",
    "# 초반 2초 데이터 삭제 (시작 안정화)\n",
    "start_time = df_ppg[\"Timestamp\"].iloc[0]\n",
    "df_ppg = df_ppg[df_ppg[\"Timestamp\"] > start_time + pd.Timedelta(seconds=2)]\n",
    "\n",
    "# PPG 신호 청소 (샘플링 주파수 25Hz)\n",
    "fs = 25\n",
    "ppg_cleaned = nk.ppg_clean(df_ppg[\"PPG\"], sampling_rate=fs)\n",
    "\n",
    "# 피크 검출 함수 (min_y 추가)\n",
    "def find_prominent_peaks(signal, threshold=0.1, min_y=0):\n",
    "    peaks = []\n",
    "    for i in range(1, len(signal) - 1):\n",
    "        if signal[i] > signal[i - 1] and signal[i] > signal[i + 1] and signal[i] > min_y:\n",
    "            left_min = min(signal[max(0, i - 5):i])\n",
    "            right_min = min(signal[i + 1:i + 6])\n",
    "            prominence = signal[i] - max(left_min, right_min)\n",
    "            if prominence > threshold:\n",
    "                peaks.append(i)\n",
    "    return peaks\n",
    "\n",
    "# 전체 신호에 대해 피크 검출\n",
    "peaks_indices = find_prominent_peaks(ppg_cleaned, threshold=0.1, min_y=0)\n",
    "peaks_timestamps = df_ppg[\"Timestamp\"].iloc[peaks_indices].values  # numpy array of timestamps\n",
    "peaks_values = ppg_cleaned[peaks_indices]\n",
    "\n",
    "# 전체 신호 및 피크 시각화 (옵션)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_ppg[\"Timestamp\"], ppg_cleaned, label=\"Cleaned PPG\", color=\"blue\")\n",
    "plt.scatter(peaks_timestamps, peaks_values, color=\"red\", label=\"Peaks\", zorder=3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"PPG Signal\")\n",
    "plt.title(\"PPG Signal with Detected Peaks\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Accelerometer 데이터 처리 및 이상 탐지 (MSPC-PCA)\n",
    "# ---------------------------\n",
    "\n",
    "# Accelerometer 데이터 읽기 및 DataFrame 생성\n",
    "accel_values = []\n",
    "accel_timestamps = []\n",
    "for key, value in data_json[\"AccelerometerData\"].items():\n",
    "    # 실제 키 이름(\"ax\", \"ay\", \"az\")는 데이터 구조에 맞게 수정하세요.\n",
    "    accel_values.append([value[\"ax\"], value[\"ay\"], value[\"az\"]])\n",
    "    accel_timestamps.append(pd.to_datetime(value[\"timestamp\"]))\n",
    "df_accel = pd.DataFrame(accel_values, columns=[\"ax\", \"ay\", \"az\"])\n",
    "df_accel[\"Timestamp\"] = accel_timestamps\n",
    "df_accel = df_accel.sort_values(\"Timestamp\")\n",
    "\n",
    "# PPG와 동일하게 초반 2초 데이터 삭제 (시작 안정화)\n",
    "start_time = df_accel[\"Timestamp\"].iloc[0]\n",
    "df_accel = df_accel[df_accel[\"Timestamp\"] > start_time + pd.Timedelta(seconds=2)]\n",
    "\n",
    "# 인덱스로 설정\n",
    "df_accel.set_index(\"Timestamp\", inplace=True)\n",
    "\n",
    "# 각 2분 윈도우마다 가속도계 데이터 대표값 도출 (평균 vs. 중앙값, CV 기준)\n",
    "def compute_feature(series):\n",
    "    mean_val = series.mean()\n",
    "    std_val = series.std()\n",
    "    cv = (std_val/mean_val * 100) if mean_val != 0 else 0\n",
    "    return series.mean() if cv < 33 else series.median()\n",
    "\n",
    "accel_features = []\n",
    "accel_intervals = []\n",
    "for window_start, group in df_accel.groupby(pd.Grouper(freq=\"2Min\")):\n",
    "    if group.empty:\n",
    "        continue\n",
    "    window_end = window_start + pd.Timedelta(minutes=2)\n",
    "    feat_x = compute_feature(group[\"ax\"])\n",
    "    feat_y = compute_feature(group[\"ay\"])\n",
    "    feat_z = compute_feature(group[\"az\"])\n",
    "    accel_features.append([feat_x, feat_y, feat_z])\n",
    "    accel_intervals.append((window_start, window_end))\n",
    "df_accel_features = pd.DataFrame(accel_features, columns=[\"feat_x\", \"feat_y\", \"feat_z\"])\n",
    "df_accel_features[\"WindowStart\"] = [interval[0] for interval in accel_intervals]\n",
    "df_accel_features[\"WindowEnd\"] = [interval[1] for interval in accel_intervals]\n",
    "\n",
    "# MSPC-PCA 이상 탐지: 단일 주성분 PCA를 사용해 Hotelling T²와 SPE 계산\n",
    "alpha = 0.05\n",
    "\n",
    "N_accel = len(df_accel_features)\n",
    "X_accel = df_accel_features[[\"feat_x\", \"feat_y\", \"feat_z\"]].values.astype(float)\n",
    "X_accel_scaled = StandardScaler().fit_transform(X_accel)\n",
    "pca_accel = PCA(n_components=1)\n",
    "scores_accel = pca_accel.fit_transform(X_accel_scaled).flatten()\n",
    "variance_accel = pca_accel.explained_variance_[0]\n",
    "T2_accel = (scores_accel**2) / variance_accel\n",
    "ulc_t2_accel = (1 * (N_accel + 1) * (N_accel - 1) / (N_accel * (N_accel - 1))) * f.ppf(1 - alpha, 1, N_accel - 1)\n",
    "X_hat_accel = pca_accel.inverse_transform(scores_accel.reshape(-1,1))\n",
    "SPE_accel = ((X_accel_scaled - X_hat_accel)**2).sum(axis=1)\n",
    "b_accel, v_accel = SPE_accel.mean(), SPE_accel.var()\n",
    "df_chi_accel = (2 * b_accel * b_accel) / v_accel\n",
    "ulc_spe_accel = (v_accel / (2 * b_accel)) * chi2.ppf(1 - alpha, df_chi_accel)\n",
    "\n",
    "df_accel_features[\"T2\"] = T2_accel\n",
    "df_accel_features[\"SPE\"] = SPE_accel\n",
    "df_accel_features[\"OOC_T2\"] = T2_accel > ulc_t2_accel\n",
    "df_accel_features[\"OOC_SPE\"] = SPE_accel > ulc_spe_accel\n",
    "df_accel_features[\"Anomaly\"] = df_accel_features[\"OOC_T2\"] | df_accel_features[\"OOC_SPE\"]\n",
    "\n",
    "# 이상 구간(2분 윈도우) 기록: 이상치인 윈도우의 시작, 종료 시간\n",
    "accel_anomaly_intervals = []\n",
    "for index, row in df_accel_features.iterrows():\n",
    "    if row[\"Anomaly\"]:\n",
    "        accel_anomaly_intervals.append((row[\"WindowStart\"], row[\"WindowEnd\"]))\n",
    "print(\"Accelerometer anomaly intervals:\", accel_anomaly_intervals)\n",
    "\n",
    "# Control Chart 시각화 — Hotelling’s T² (Accelerometer)\n",
    "plt.figure()\n",
    "plt.plot(df_accel_features[\"WindowStart\"], T2_accel, marker=\"o\")\n",
    "plt.axhline(ulc_t2_accel, linestyle=\"--\", color=\"red\", label=\"ULC T²\")\n",
    "plt.title(\"Accelerometer Domain — Hotelling’s T²\")\n",
    "plt.xlabel(\"Window Start\")\n",
    "plt.ylabel(\"T²\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Control Chart 시각화 — SPE (Accelerometer)\n",
    "plt.figure()\n",
    "plt.plot(df_accel_features[\"WindowStart\"], SPE_accel, marker=\"o\")\n",
    "plt.axhline(ulc_spe_accel, linestyle=\"--\", color=\"red\", label=\"ULC SPE\")\n",
    "plt.title(\"Accelerometer Domain — SPE\")\n",
    "plt.xlabel(\"Window Start\")\n",
    "plt.ylabel(\"SPE\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 이상 구간 출력 (Accelerometer)\n",
    "ooc_accel = df_accel_features[df_accel_features[\"OOC_T2\"] | df_accel_features[\"OOC_SPE\"]]\n",
    "print(\"\\n=== Accelerometer Domain Out‑of‑Control Segments ===\")\n",
    "print(ooc_accel[[\"WindowStart\", \"WindowEnd\", \"OOC_T2\", \"OOC_SPE\"]])\n",
    "\n",
    "# ---------------------------\n",
    "# 3. PPG 데이터 필터링: accelerometer 이상 구간 제거\n",
    "# ---------------------------\n",
    "def is_in_anomaly(timestamp, anomaly_intervals):\n",
    "    for start, end in anomaly_intervals:\n",
    "        if start <= timestamp <= end:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df_ppg_filtered = df_ppg[~df_ppg[\"Timestamp\"].apply(lambda t: is_in_anomaly(t, accel_anomaly_intervals))]\n",
    "print(f\"Original PPG count: {len(df_ppg)}, Filtered count: {len(df_ppg_filtered)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4. PPG 신호 전처리: 필터링된 PPG 데이터로 HRV 및 MSPC-PCA 이상 탐지 수행\n",
    "# ---------------------------\n",
    "ppg_cleaned_filtered = nk.ppg_clean(df_ppg_filtered[\"PPG\"], sampling_rate=fs)\n",
    "peaks_indices_filtered = find_prominent_peaks(ppg_cleaned_filtered, threshold=0.1, min_y=0)\n",
    "peaks_timestamps_filtered = df_ppg_filtered[\"Timestamp\"].iloc[peaks_indices_filtered].values\n",
    "peaks_values_filtered = ppg_cleaned_filtered[peaks_indices_filtered]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_ppg_filtered[\"Timestamp\"], ppg_cleaned_filtered, label=\"Cleaned PPG (Filtered)\", color=\"blue\")\n",
    "plt.scatter(peaks_timestamps_filtered, peaks_values_filtered, color=\"red\", label=\"Peaks (Filtered)\", zorder=3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"PPG Signal\")\n",
    "plt.title(\"PPG Signal with Detected Peaks (Filtered by Accelerometer Anomalies)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 5. 피크 기준으로 2분 단위 HRV 분석\n",
    "# ----------------------------------------------------\n",
    "hrv_results = []\n",
    "i = 0\n",
    "peaks_ts = peaks_timestamps_filtered\n",
    "while i < len(peaks_ts):\n",
    "    seg_start = peaks_ts[i]\n",
    "    seg_end = seg_start + pd.Timedelta(minutes=2)\n",
    "    segment_peaks = []\n",
    "    while i < len(peaks_ts) and peaks_ts[i] < seg_end:\n",
    "        segment_peaks.append(peaks_indices_filtered[i])\n",
    "        i += 1\n",
    "    if len(segment_peaks) < 2:  \n",
    "        print(f\"구간 {seg_start} ~ {seg_end} 에는 피크가 부족하여 HRV 계산을 건너뜁니다.\")\n",
    "        continue\n",
    "    \n",
    "    # HR 시리즈 생성 (bpm)\n",
    "    segment_times = peaks_ts[i - len(segment_peaks):i]  # datetime64 array\n",
    "    rri = np.diff(segment_times).astype(\"timedelta64[ms]\").astype(int)  # ms 단위 RR intervals\n",
    "    hr_series = 60000 / rri\n",
    "    \n",
    "    hrv_time = nk.hrv_time(segment_peaks, sampling_rate=25)\n",
    "    hrv_time_metrics = {\n",
    "        \"mean_nni\": hrv_time[\"HRV_MeanNN\"].iloc[0],\n",
    "        \"median_nni\": hrv_time[\"HRV_MedianNN\"].iloc[0],\n",
    "        \"range_nni\": hrv_time[\"HRV_MaxNN\"].iloc[0] - hrv_time[\"HRV_MinNN\"].iloc[0],\n",
    "        \"sdnn\": hrv_time[\"HRV_SDNN\"].iloc[0],\n",
    "        \"sdsd\": hrv_time[\"HRV_SDSD\"].iloc[0],\n",
    "        \"rmssd\": hrv_time[\"HRV_RMSSD\"].iloc[0],\n",
    "        \"nni_50\": int(np.sum(np.abs(np.diff(rri)) > 50)),\n",
    "        \"pnni_50\": hrv_time[\"HRV_pNN50\"].iloc[0],\n",
    "        \"nni_20\": int(np.sum(np.abs(np.diff(rri)) > 20)),\n",
    "        \"pnni_20\": hrv_time[\"HRV_pNN20\"].iloc[0],\n",
    "        \"cvsd\": hrv_time[\"HRV_CVSD\"].iloc[0],\n",
    "        \"cvnni\": hrv_time[\"HRV_CVNN\"].iloc[0],\n",
    "        \"mean_hr\": np.nanmean(hr_series),\n",
    "        \"min_hr\": np.nanmin(hr_series),\n",
    "        \"max_hr\": np.nanmax(hr_series),\n",
    "        \"std_hr\": np.nanstd(hr_series, ddof=1),\n",
    "    }\n",
    "    \n",
    "    # 주파수 영역 HRV 계산\n",
    "    hrv_freq = nk.hrv_frequency(segment_peaks, sampling_rate=25, normalize=False)\n",
    "    if not hrv_freq.empty:\n",
    "        hrv_freq_metrics = {\n",
    "            \"power_vlf\": hrv_freq[\"HRV_VLF\"].iloc[0],\n",
    "            \"power_lf\":  hrv_freq[\"HRV_LF\"].iloc[0],\n",
    "            \"power_hf\":  hrv_freq[\"HRV_HF\"].iloc[0],\n",
    "            \"total_power\": hrv_freq[\"HRV_TP\"].iloc[0],\n",
    "            \"lf_hf_ratio\": hrv_freq[\"HRV_LFHF\"].iloc[0]\n",
    "        }\n",
    "    else:\n",
    "        hrv_freq_metrics = {k: np.nan for k in [\"power_vlf\",\"power_lf\",\"power_hf\",\"total_power\",\"lf_hf_ratio\"]}\n",
    "    \n",
    "    # 비선형 영역 주파수 계산\n",
    "    hrv_nonlinear = nk.hrv_nonlinear(segment_peaks, sampling_rate=25)\n",
    "    if not hrv_nonlinear.empty:\n",
    "        hrv_nonlinear_metrics = {\n",
    "            \"csi\":            hrv_nonlinear[\"HRV_CSI\"].iloc[0],\n",
    "            \"cvi\":            hrv_nonlinear[\"HRV_CVI\"].iloc[0],\n",
    "            \"modified_csi\":   hrv_nonlinear[\"HRV_CSI_Modified\"].iloc[0],\n",
    "            \"sampen\":         hrv_nonlinear[\"HRV_SampEn\"].iloc[0],\n",
    "        }\n",
    "    else:\n",
    "        hrv_nonlinear_metrics = {k: np.nan for k in [\"csi\",\"cvi\",\"modified_csi\",\"sampen\"]}\n",
    "    \n",
    "    \n",
    "    result = {\n",
    "        \"Segment Start\": seg_start,\n",
    "        \"Segment End\": seg_end,\n",
    "        \"HRV Time Metrics\": hrv_time_metrics,\n",
    "        \"HRV Frequency Metrics\": hrv_freq_metrics,\n",
    "        \"HRV Nonlinear Metrics\": hrv_nonlinear_metrics\n",
    "    }\n",
    "    hrv_results.append(result)\n",
    "\n",
    "# HRV 결과를 하나의 DataFrame으로 결합하기\n",
    "results_list = []\n",
    "for res in hrv_results:\n",
    "    row = {\n",
    "        \"Segment Start\": res[\"Segment Start\"],\n",
    "        \"Segment End\":   res[\"Segment End\"]\n",
    "    }\n",
    "    # Time-domain dict → Time_ 접두어\n",
    "    for key, val in res[\"HRV Time Metrics\"].items():\n",
    "        row[f\"Time_{key}\"] = val\n",
    "\n",
    "    # Frequency-domain dict → Freq_ 접두어\n",
    "    for key, val in res[\"HRV Frequency Metrics\"].items():\n",
    "        row[f\"Freq_{key}\"] = val\n",
    "\n",
    "    # Nonlinear-domain dict → Nonlinear_ 접두어\n",
    "    for key, val in res[\"HRV Nonlinear Metrics\"].items():\n",
    "        row[f\"Nonlinear_{key}\"] = val\n",
    "\n",
    "    results_list.append(row)\n",
    "\n",
    "df_hrv_results = pd.DataFrame(results_list)\n",
    "\n",
    "# --- 딕셔너리 → DataFrame 생성 ---\n",
    "df_segment = pd.DataFrame({\n",
    "    \"Time\": pd.Series(res[\"HRV Time Metrics\"]),\n",
    "    \"Frequency\": pd.Series(res[\"HRV Frequency Metrics\"]),\n",
    "    \"Nonlinear\": pd.Series(res[\"HRV Nonlinear Metrics\"])\n",
    "})\n",
    "\n",
    "\n",
    "start_str = pd.to_datetime(seg_start).strftime(\"%H:%M:%S\")\n",
    "end_str   = pd.to_datetime(seg_end).strftime(\"%H:%M:%S\")\n",
    "# 출력\n",
    "print(f\"\\n===== Segment {start_str} → {end_str} =====\")\n",
    "print(df_segment.round(3))\n",
    "\n",
    "\n",
    "# HRV 결과 CSV 파일로 저장하려면 여기 사용용\n",
    "df_hrv_results.to_csv(\"hrv_results.csv\", index=False)\n",
    "print(\"HRV 결과가 hrv_results.csv 파일에 저장되었습니다.\")\n",
    "\n",
    "# ---------------------------\n",
    "# 6. MSPC-PCA 이상 탐지 on HRV (각 도메인별)\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "\n",
    "N = len(df_hrv_results)\n",
    "\n",
    "# 도메인별 컬럼 매핑\n",
    "domains = {\n",
    "    \"Time\": df_hrv_results.filter(regex=\"^Time_\").columns,\n",
    "    \"Freq\": df_hrv_results.filter(regex=\"^Freq_\").columns,\n",
    "    \"Nonlinear\": df_hrv_results.filter(regex=\"^Nonlinear_\").columns\n",
    "}\n",
    "\n",
    "for domain, cols in domains.items():\n",
    "    # 1) 데이터 준비 및 표준화\n",
    "    X = df_hrv_results[cols].fillna(0).values.astype(float)\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # 2) PCA (단일 주성분)\n",
    "    pca = PCA(n_components=1)\n",
    "    scores = pca.fit_transform(X_scaled).flatten()\n",
    "    variance = pca.explained_variance_[0]\n",
    "\n",
    "    # 3) Hotelling’s T² 계산\n",
    "    T2 = (scores ** 2) / variance\n",
    "    ulc_t2 = (1 * (N + 1) * (N - 1) / (N * (N - 1))) * f.ppf(1 - alpha, 1, N - 1)\n",
    "\n",
    "    # 4) SPE (Q‑statistic) 계산\n",
    "    X_hat = pca.inverse_transform(scores.reshape(-1, 1))\n",
    "    SPE = ((X_scaled - X_hat) ** 2).sum(axis=1)\n",
    "    b, v = SPE.mean(), SPE.var()\n",
    "    df_chi = (2 * b * b) / v\n",
    "    ulc_spe = (v / (2 * b)) * chi2.ppf(1 - alpha, df_chi)\n",
    "\n",
    "    # 5) 결과 DataFrame 추가\n",
    "    df_hrv_results[f\"{domain}_T2\"] = T2\n",
    "    df_hrv_results[f\"{domain}_SPE\"] = SPE\n",
    "    df_hrv_results[f\"{domain}_OOC_T2\"] = T2 > ulc_t2\n",
    "    df_hrv_results[f\"{domain}_OOC_SPE\"] = SPE > ulc_spe\n",
    "\n",
    "    # 6) Control Chart 시각화 — Hotelling’s T²\n",
    "    plt.figure()\n",
    "    plt.plot(df_hrv_results[\"Segment Start\"], T2, marker=\"o\")\n",
    "    plt.axhline(ulc_t2, linestyle=\"--\")\n",
    "    plt.title(f\"{domain} Domain — Hotelling’s T²\")\n",
    "    plt.xlabel(\"Segment Start\")\n",
    "    plt.ylabel(\"T²\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 7) Control Chart 시각화 — SPE\n",
    "    plt.figure()\n",
    "    plt.plot(df_hrv_results[\"Segment Start\"], SPE, marker=\"o\")\n",
    "    plt.axhline(ulc_spe, linestyle=\"--\")\n",
    "    plt.title(f\"{domain} Domain — SPE\")\n",
    "    plt.xlabel(\"Segment Start\")\n",
    "    plt.ylabel(\"SPE\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 8) 이상구간 출력\n",
    "    ooc = df_hrv_results[df_hrv_results[f\"{domain}_OOC_T2\"] | df_hrv_results[f\"{domain}_OOC_SPE\"]]\n",
    "    print(f\"\\n=== {domain} Domain Out‑of‑Control Segments ===\")\n",
    "    print(ooc[[\"Segment Start\",\"Segment End\",f\"{domain}_OOC_T2\",f\"{domain}_OOC_SPE\"]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neourokit2를 사용해 peak를 구하는 함수 peak는 정확하지만 탐지하지 못하는 peak가 있음\n",
    "# 필요 라이브러리 임포트\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, db\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if firebase_admin._apps:\n",
    "    firebase_admin.delete_app(firebase_admin.get_app())\n",
    "\n",
    "# 🔹 Firebase 앱 새로 초기화\n",
    "cred = credentials.Certificate(\"hrvdataset-firebase-adminsdk-oof96-2a96d6ac7f.json\")  # Firebase Admin SDK JSON 파일\n",
    "firebase_admin.initialize_app(cred, {\"databaseURL\": \"https://hrvdataset-default-rtdb.firebaseio.com/\"})\n",
    "\n",
    "ref = db.reference(\"HeartRateData\")\n",
    "data = ref.get()\n",
    "\n",
    "# 데이터 정리\n",
    "ppg_values = []\n",
    "timestamps = []\n",
    "\n",
    "for key, value in data.items():\n",
    "    if not value[\"isError\"]:  # 오류 없는 데이터만 사용\n",
    "        ppg_values.append(value[\"ppgGreen\"])\n",
    "        timestamps.append(pd.to_datetime(value[\"timestamp\"]))\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({\"Timestamp\": timestamps, \"PPG\": ppg_values})\n",
    "df = df.sort_values(\"Timestamp\")  # 시간 순 정렬\n",
    "\n",
    "# 초반 2초의 데이터를 삭제\n",
    "start_time = df[\"Timestamp\"].iloc[0]\n",
    "df = df[df[\"Timestamp\"] > start_time + pd.Timedelta(seconds=2)]\n",
    "\n",
    "# PPG 신호 처리 (25Hz 가정)\n",
    "fs = 25  # 샘플링 주파수\n",
    "ppg_cleaned = nk.ppg_clean(df[\"PPG\"], sampling_rate=fs)\n",
    "\n",
    "# PPG 피크 검출\n",
    "peaks, info = nk.ppg_peaks(ppg_cleaned, sampling_rate=fs)\n",
    "\n",
    "# peaks 데이터프레임의 인덱스를 df와 일치시키기\n",
    "peaks[\"Timestamp\"] = df[\"Timestamp\"].reset_index(drop=True)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[\"Timestamp\"], ppg_cleaned, label=\"Cleaned PPG\", color=\"blue\")\n",
    "plt.scatter(peaks[\"Timestamp\"][peaks[\"PPG_Peaks\"] == 1], ppg_cleaned[peaks[\"PPG_Peaks\"] == 1], color=\"red\", label=\"Peaks\", zorder=3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"PPG Signal\")\n",
    "plt.title(\"PPG Signal with Detected Peaks\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
